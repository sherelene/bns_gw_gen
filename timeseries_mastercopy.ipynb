{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "timeseries_mastercopy.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4x0tyVUhCVFi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f51aa484-85e2-45c4-b750-a317ed586e7d"
      },
      "source": [
        "#!pip install pycbc lalsuite ligo-common \n",
        "#!pip install gwpy\n",
        "\n",
        "#run previous lines if install -q code doesnt work\n",
        "! pip install -q 'lalsuite==6.66' 'bilby==0.6.1' 'gwpy==1.0.1'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 28.5 MB 67 kB/s \n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 39.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 40.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 18.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 87 kB 5.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 45 kB 3.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 34.1 MB/s \n",
            "\u001b[?25h  Building wheel for bilby (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ligo-segments (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for lscsoft-glue (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0h8IFwLfBpI"
      },
      "source": [
        "import gwpy\n",
        "from gwpy.timeseries import TimeSeries"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIENpS1rhZen"
      },
      "source": [
        "#uncomment and run this block of code instead if import gwpy and TimeSeries doesnt work\n",
        "'''from __future__ import division, print_function\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import bilby\n",
        "from bilby.core.prior import Uniform\n",
        "from bilby.gw.conversion import convert_to_lal_binary_black_hole_parameters, generate_all_bbh_parameters\n",
        "\n",
        "from gwpy.timeseries import TimeSeries''' "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRXMoY7HBLRk"
      },
      "source": [
        "! git clone https://github.com/matteobreschi/bajes.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXePtjaxBmW3"
      },
      "source": [
        "%cd bajes\n",
        "! ls\n",
        "! python setup.py install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFRkA4cCo6h1"
      },
      "source": [
        "#necessary to run TEOBResumS_NRPM approx but not necessary if using only NRPM\n",
        "! git clone https://RoxGamba@bitbucket.org/eob_ihes/teobresums.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsC6g8Wko9aF"
      },
      "source": [
        "! apt update\n",
        "! apt install build-essential\n",
        "! apt-get install -y libconfig-dev\n",
        "!apt-get install libgsl-dev\n",
        "% cd teobresums/Python/\n",
        "!python TEOBResumSWrap_setup.py install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIQ79R4HCljv"
      },
      "source": [
        "from __future__ import division, print_function\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from bajes.bajes.obs.gw import Series\n",
        "from bajes.bajes.obs.gw import Noise\n",
        "from bajes.bajes.obs.gw.utils import read_asd\n",
        "import csv"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Exgz3VaL-5eo"
      },
      "source": [
        "#import drive so csv file wont just save during runtime\n",
        "from google.colab import drive \n",
        "drive.mount('/content/drive/', force_remount = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btCJOgMXMV1E"
      },
      "source": [
        "time_of_event = 1126259462.4\n",
        "\n",
        "post_trigger_duration =4\n",
        "duration = 8\n",
        "analysis_start = time_of_event + post_trigger_duration - duration\n",
        "\n",
        "# Use gwpy to fetch the open data\n",
        "H1_analysis_data = TimeSeries.fetch_open_data(\n",
        "    \"H1\", analysis_start, analysis_start + duration, sample_rate=4096, cache=True)\n",
        "\n",
        "t = H1_analysis_data.times\n",
        "strain = H1_analysis_data.value\n",
        "\n",
        "# set the data properties coherently\n",
        "seglen = 8           # duration of the segment [s]\n",
        "srate  = 4096         # sampling rate [Hz]\n",
        "t_gps  = 0  # central value of GPS time\n",
        "f_max  = 1024\n",
        "f_min  = 20 \n",
        "\n",
        "series = Series('time', strain, seglen=seglen, srate=srate, t_gps=t_gps, f_min=f_min, f_max=f_max)\n",
        "print('here')\n",
        "from bajes.bajes.obs.gw import Noise\n",
        "from bajes.bajes.obs.gw.utils import read_asd\n",
        "\n",
        "fr_asd, asd = read_asd('GW150914', 'H1')\n",
        "noise       = Noise(fr_asd, asd, f_min=0, f_max=f_max)\n",
        "\n",
        "from bajes.bajes.obs.gw import Detector, Waveform\n",
        "\n",
        "wave  = Waveform(series.freqs, srate, seglen, 'TEOBResumS_NRPM') #NRPM for postmergers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNTl2OSBSBwK"
      },
      "source": [
        "\n",
        "for num in range(20000):\n",
        "  from scipy.interpolate import interpolate as interp\n",
        "\n",
        "  eosdir = '/content/drive/MyDrive/Colab_Notebooks/macro'\n",
        "  numeos = 2396\n",
        "\n",
        "\n",
        "  def get_mmax(eos_id):\n",
        "    eospath = eosdir+\"/macro-spec_%dcr.csv\" % eos_id\n",
        "    eos_data = np.genfromtxt(eospath, names=True, delimiter=\",\")\n",
        "    marray =  eos_data[\"M\"]\n",
        "    mmax_pos   = np.argmax(marray)\n",
        "    mmax = marray[mmax_pos]\n",
        "    return mmax\n",
        "\n",
        "  def get_lambda_from_masses(m1, m2, eos_id):\n",
        "\n",
        "    eospath = eosdir+\"/macro-spec_%dcr.csv\" % eos_id\n",
        "    eos_data = np.genfromtxt(eospath, names=True, delimiter=\",\")\n",
        "    marray, larray =  eos_data[\"M\"], eos_data[\"Lambda\"]\n",
        "    mmax_pos   = np.argmax(marray)\n",
        "    marray, larray = marray[0:mmax_pos+1], larray[0:mmax_pos+1]\n",
        "    mmax = marray[mmax_pos]\n",
        "\n",
        "    assert m1 <= mmax and m2 <= mmax, \"Error: one or both masses too heavy for a NS!\"\n",
        "\n",
        "    f_lambda = interp.interp1d(marray, larray, fill_value=0, bounds_error=False)\n",
        "    lambda1, lambda2 = f_lambda(m1), f_lambda(m2)\n",
        "\n",
        "    assert lambda2 >= lambda1, \"Error: Lambda1 is larger than Lambda2 for common EOS!\"\n",
        "\n",
        "    return lambda1, lambda2\n",
        "\n",
        "  \n",
        "  import math\n",
        "  import random\n",
        "  eos_id = np.random.choice(range(numeos), 1)\n",
        "  mmax = get_mmax(eos_id)\n",
        "\n",
        "  m1 = random.uniform(1, mmax) \n",
        "  m2 = random.uniform(1, mmax)\n",
        "\n",
        "  # m1 has to be bigger than m2 for the proper mass ratio \n",
        "  if m1 > m2:\n",
        "    chirp_mass = (math.pow((m1 * m2), (3/5))) / (math.pow((m1 + m2), (1/5))) \n",
        "    q = m1 / m2  #calculates the mass ratio\n",
        "  elif m1 < m2:\n",
        "    while m1 < m2:\n",
        "      m1 = random.uniform(1, mmax)\n",
        "      m2 = random.uniform(1, mmax)\n",
        "  chirp_mass = (math.pow((m1 * m2), (3/5))) / (math.pow((m1 + m2), (1/5)))\n",
        "  q = m1 / m2\n",
        "\n",
        "  lambda1, lambda2 = get_lambda_from_masses(m1, m2, eos_id)\n",
        "\n",
        "  params = {'mchirp'       : chirp_mass,    # chirp mass [solar masses] \n",
        "              'q'          : q,      # mass ratio \n",
        "              's1x'        : 0.,      # primary spin parameter, x component\n",
        "              's1y'        : 0.,      # primary spin parameter, y component\n",
        "              's1z'        : 0.,      # primary spin parameter, z component\n",
        "              's2x'        : 0.,      # secondary spin parameter, x component\n",
        "              's2y'        : 0.,      # secondary spin parameter, y component\n",
        "              's2z'        : 0.,      # secondary spin parameter, z component\n",
        "              'lambda1'    : lambda1,    # primary tidal parameter \n",
        "              'lambda2'    : lambda2,    # secondary tidal parameter\n",
        "              'distance'   : 100.8114416513031,    # distance [Mpc]   \n",
        "              'iota'       : np.pi,   # inclination [rad]   \n",
        "              'ra'         : 0.,     # right ascension [rad]\n",
        "              'dec'        : 0.,   # declination [rad]\n",
        "              'psi'        : 0.,      # polarization angle [rad]\n",
        "              'time_shift' : 0.419,   # time shift from GPS time [s]\n",
        "              'phi_ref'    : 0.,      # phase shift [rad]\n",
        "              'f_min'      : 20.,     # minimum frequency [Hz]\n",
        "              'srate'      : srate,   # sampling rate [Hz]\n",
        "              'seglen'     : seglen,  # segment duration [s] \n",
        "              'tukey'      : 0.1,     # parameter for tukey window\n",
        "              't_gps'      : t_gps,   # GPS trigger time\n",
        "              'lmax'       : 0.,\n",
        "              'eccentricity' : 0.\n",
        "             }  \n",
        "\n",
        "  hpc = wave.compute_hphc(params)\n",
        "\n",
        "\n",
        "  new_params = params #put params in new dictionary\n",
        "  new_params[\"m1\"] = m1 #add m1 to new dictionary\n",
        "  new_params[\"m2\"] = m2 #add m2 to new dictionary\n",
        "  new_params[\"mtot\"] = round((m1 + m2), 1) #change mtot from params into a float with only 1 decimal point\n",
        "\n",
        "\n",
        " #the very first run of the code, next_simulation is set at 1\n",
        " #if eos code throws an error while being iterated, change the next_simulation variable to the last simulation number + 1 so if \n",
        " #last simulation file name number is S00051 then in the next_simulation variable, put the number 52\n",
        "  next_simulation = 1\n",
        "  if num == 0:\n",
        "    new_num = num + next_simulation\n",
        "  else:\n",
        "    new_num = new_num + 1\n",
        "\n",
        "  #changes the file name for each sim run\n",
        "  if new_num <= 9:\n",
        "    leading_zeros = \"S0000\"\n",
        "  elif new_num <= 99:\n",
        "    leading_zeros = \"S000\"\n",
        "  elif new_num <= 999:\n",
        "    leading_zeros = \"S00\"\n",
        "  elif new_num <= 9999:\n",
        "    leading_zeros = \"S0\"\n",
        "  else:\n",
        "    leading_zeros = \"S\"\n",
        "\n",
        "  new_params[\"file name\"] = f\"{leading_zeros}{new_num}.csv\"\n",
        "  text_file = f'/content/drive/MyDrive/Colab_Notebooks/time_series/new_sims/{leading_zeros}{new_num}.csv'\n",
        "\n",
        "  #separates the time series into two columns so it can be in a dataframe\n",
        "  x = series.times\n",
        "  y = hpc.plus\n",
        "  ts_df= pd.DataFrame({'time': x, 'strain': y})\n",
        "\n",
        "  #deletes rows from original dataframe so the time series csv will only be between -0.6 and +0.6 seconds\n",
        "  ts_df.drop(ts_df.index[0:16138], 0, inplace = True)\n",
        "  ts_df.drop(ts_df.index[493:], 0, inplace = True)\n",
        "  #formats dataframe\n",
        "  ts_df.to_csv(text_file, sep= '\\t', header = None, index = False) \n",
        "\n",
        "  #creates original metadata file then appends the subsequent iterations\n",
        "  if new_num == 1:\n",
        "    df = pd.DataFrame.from_dict([new_params])\n",
        "    df.to_csv('/content/drive/MyDrive/Colab_Notebooks/metadata_new.csv', sep= '\\t', index = False)\n",
        "  else: \n",
        "    from csv import DictWriter\n",
        "\n",
        "    def append_dict_as_row(file_name, dict_of_elem, field_names):\n",
        "      # Open file in append mode\n",
        "        with open(file_name, 'a+', newline='') as write_obj:\n",
        "          # Create a writer object from csv module\n",
        "            dict_writer = DictWriter(write_obj, delimiter = '\\t', fieldnames=field_names)\n",
        "            # Add dictionary as row in the csv\n",
        "            dict_writer.writerow(dict_of_elem)\n",
        "\n",
        "    field_names = ['mchirp', 'q', 's1x', 's1y', 's1z', 's2x', 's2y', 's2z', \n",
        "               'lambda1', 'lambda2', 'distance','iota', 'ra', 'dec', 'psi','time_shift',\n",
        "               'phi_ref', 'f_min', 'srate', 'seglen', 'tukey', 't_gps', 'lmax', 'eccentricity', 'm1', 'm2', 'mtot', 'file name'\n",
        "               ]  \n",
        "\n",
        "    row_dict = new_params\n",
        "    # Append a dict as a row in csv file\n",
        "    append_dict_as_row('/content/drive/MyDrive/Colab_Notebooks/metadata_new.csv', row_dict, field_names)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}